{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms as T\n",
    "import scipy.io \n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "pa_100k_group_order = [7,8,13,14,15,16,17,18,19,20,21,22,23,24,25,9,10,11,12,1,2,3,0,4,5,6]\n",
    "pa_100k_num_in_group = [2, 6, 6, 1, 4, 3, 1, 3]\n",
    "\n",
    "\n",
    "class PA100KDataset(Dataset):\n",
    "    def __init__(self, root_dir, transforms, split, use_multitask=False):\n",
    "        self.annotations = scipy.io.loadmat(\"./data/PA-100K/annotation.mat\")\n",
    "        self.file_paths = self.annotations[f\"{split}_images_name\"]\n",
    "        self.labels = self.annotations[f\"{split}_label\"]\n",
    "        self.root_dir = root_dir\n",
    "        self.transforms = transforms\n",
    "        self.use_multitask = use_multitask\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.file_paths[index][0][0]\n",
    "        image = Image.open(os.path.join(self.root_dir, image_path))\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        if self.use_multitask:\n",
    "            group_label = []\n",
    "            label = self.labels[index]\n",
    "\n",
    "            for group in range(len(pa_100k_num_in_group)):\n",
    "                group_num = pa_100k_num_in_group[group]\n",
    "                start_index = pa_100k_group_order[sum(pa_100k_num_in_group[:group])]\n",
    "                end_index = pa_100k_group_order[sum(pa_100k_num_in_group[:group]) + group_num + 1]\n",
    "                print(start_index, end_index)\n",
    "                group_label.append(np.argmax(self.labels[index][start_index:end_index]))\n",
    "            return group_label\n",
    "\n",
    "        label = self.labels[index]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PA100KDataset(\n",
    "    root_dir=\"./data/PA-100K/release_data/release_data\", \n",
    "    transforms=T.ToTensor(), \n",
    "    split=\"train\", \n",
    "    use_multitask=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 14\n",
      "13 20\n",
      "19 9\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmax of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 39\u001b[0m, in \u001b[0;36mPA100KDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     37\u001b[0m         end_index \u001b[38;5;241m=\u001b[39m pa_100k_group_order[\u001b[38;5;28msum\u001b[39m(pa_100k_num_in_group[:group]) \u001b[38;5;241m+\u001b[39m group_num \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28mprint\u001b[39m(start_index, end_index)\n\u001b[0;32m---> 39\u001b[0m         group_label\u001b[38;5;241m.\u001b[39mappend(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart_index\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m group_label\n\u001b[1;32m     42\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[index]\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36margmax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/bach_pytorch/lib/python3.11/site-packages/numpy/core/fromnumeric.py:1242\u001b[0m, in \u001b[0;36margmax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m \u001b[38;5;124;03mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;124;03m(2, 1, 4)\u001b[39;00m\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1241\u001b[0m kwds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m-> 1242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43margmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bach_pytorch/lib/python3.11/site-packages/numpy/core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mValueError\u001b[0m: attempt to get argmax of an empty sequence"
     ]
    }
   ],
   "source": [
    "dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from st_moe_pytorch import MoE\n",
    "\n",
    "moe = MoE(\n",
    "    dim = 512,\n",
    "    num_experts = 4,               # increase the experts (# parameters) of your model without increasing computation\n",
    "    gating_top_n = 2,               # default to top 2 gating, but can also be more (3 was tested in the paper with a lower threshold)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MoETransformer(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads, num_experts):\n",
    "        super(MoETransformer, self).__init__()\n",
    "        self.multihead_attn = nn.MultiheadAttention(input_dim, num_heads, batch_first=True)\n",
    "        self.moelayer = MoE(dim=input_dim, num_experts=num_experts)\n",
    "        self.norm1 = nn.LayerNorm(input_dim)\n",
    "        self.norm2 = nn.LayerNorm(input_dim)\n",
    "    \n",
    "    def forward(self, q, k, v):\n",
    "        attn_output, _ = self.multihead_attn(q, k, v)\n",
    "        \n",
    "        x = self.norm1(q + attn_output)\n",
    "        moe_output, total_aux_loss, _, _ = self.moelayer(x)\n",
    "        x = self.norm2(x + moe_output)\n",
    "        return x, total_aux_loss\n",
    "    \n",
    "class MoEFusionHead(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads, num_experts):\n",
    "        super(MoEFusionHead, self).__init__()\n",
    "        self.transformer = MoETransformer(input_dim, num_heads, num_experts)\n",
    "        self.pooling = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(input_dim, 1)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        outputs, aux_loss = self.transformer(x1, x2, x2)\n",
    "        outputs = self.pooling(outputs.transpose(1, 2)).squeeze(-1)\n",
    "        return self.fc(outputs), aux_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "features1 = torch.rand(1, 49, 768)\n",
    "features2 = torch.rand(1, 197, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 197, 768])\n",
      "torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "fusion_layer = MoEFusionHead(768, 2, 4)\n",
    "outs, loss = fusion_layer(features2, features1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bach_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
